{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# from mediapipe.tasks import python\n",
    "# from mediapipe.tasks.python import vision"
   ],
   "metadata": {
    "id": "1Jr90x3vizF7",
    "ExecuteTime": {
     "end_time": "2025-08-05T12:23:43.982782Z",
     "start_time": "2025-08-05T12:23:43.969398Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# # initialize model\n",
    "# base_options = mp.tasks.BaseOptions(model_asset_path='pose_landmarker_lite.task')\n",
    "# options = mp.tasks.vision.PoseLandmarkerOptions(base_options=base_options)\n",
    "# pose_landmarker = mp.tasks.vision.PoseLandmarker.create_from_options(options)"
   ],
   "metadata": {
    "id": "b4RPUufHjD3l",
    "ExecuteTime": {
     "end_time": "2025-08-05T12:23:44.014991Z",
     "start_time": "2025-08-05T12:23:43.998901Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9fb678cc",
    "ExecuteTime": {
     "end_time": "2025-08-05T12:23:44.030627Z",
     "start_time": "2025-08-05T12:23:44.014991Z"
    }
   },
   "source": [
    "# # Load into Array\n",
    "# image_path = '/content/hand.jpg'\n",
    "# image = cv2.imread(image_path)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "# '''\n",
    "# Convert it to RGB, and reads image into memory into array cv2.imread(filename, flags=cv2.IMREAD_COLOR)\n",
    "# flags:\n",
    "# cv2.IMREAD_COLOR (default): Loads the image in BGR color format.\n",
    "# cv2.IMREAD_GRAYSCALE: Loads the image in grayscale format.\n",
    "# cv2.IMREAD_UNCHANGED: Loads the image as such including alpha channel.\n",
    "# '''\n",
    "# image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "# '''\n",
    "# MediaPipe performs poorly on very small or very large images.\n",
    "# Best results: images around 480‚Äì720px in height\n",
    "# If needed, resize:\n",
    "# '''\n",
    "# image_rgb = cv2.resize(image_rgb, (640, 480))\n",
    "# '''\n",
    "# # Wrap the image in MediaPipe's Image object\n",
    "# # Wraps a NumPy image array into a format that MediaPipe‚Äôs models understand.\n",
    "# '''\n",
    "# mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image_rgb)"
   ],
   "metadata": {
    "id": "rWehqFcAkq5N",
    "ExecuteTime": {
     "end_time": "2025-08-05T12:23:44.078430Z",
     "start_time": "2025-08-05T12:23:44.062771Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# #Initialize pose landmarker\n",
    "\n",
    "# '''\n",
    "# python.BaseOptions(str model_asset_path\t= .task model file)\n",
    "# üß† Purpose:\n",
    "# This class defines basic settings for how the ML model is loaded and run.\n",
    "# '''\n",
    "# base_options = python.BaseOptions('/content/pose_landmarker_lite.task')\n",
    "\n",
    "# '''\n",
    "# vision.PoseLandmarkerOptions(base_options, running_mode: Enum: IMAGE, VIDEO, or LIVE_STREAM, num_poses = 1(default))\n",
    "# This class allows you to configure how the pose landmarker behaves\n",
    "# Config\n",
    "# '''\n",
    "# options = vision.PoseLandmarkerOptions(base_options=base_options)\n",
    "# '''\n",
    "# PoseLandmarker.create_from_options(options)\n",
    "# üß† Purpose:\n",
    "# This is a factory method that creates the actual pose detection object you‚Äôll use.\n",
    "# options - \tPoseLandmarkerOptions\n",
    "# returns:\n",
    "# a PoseLandmarker object that can now:\n",
    "\n",
    "#   Detect poses from a single image\n",
    "\n",
    "#   Detect from a webcam (if LIVE_STREAM)\n",
    "\n",
    "#   Give you access to all 33 body landmarks\n",
    "# '''\n",
    "# pose_landmarker = vision.PoseLandmarker.create_from_options(options)"
   ],
   "metadata": {
    "id": "cYhGQllgmz4-",
    "ExecuteTime": {
     "end_time": "2025-08-05T12:23:44.110194Z",
     "start_time": "2025-08-05T12:23:44.094455Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# # üìç 4. Run Detection on the Image\n",
    "# '''\n",
    "# pose_landmarker.detect(mp_image)\n",
    "# üß† What does it do?\n",
    "# This function analyzes the image, detects any human body poses, and returns the 33 body landmarks for each detected person.\n",
    "# mp_image = mp.image object which model can understand\n",
    "# A list of poses, each with 33 key points (landmarks).\n",
    "# x, y, z, visibility\n",
    "# '''\n",
    "# detection_result = pose_landmarker.detect(mp_image)\n",
    "# landmarks = detection_result.pose_landmarks[0]  # Only 1 person assumed\n",
    "\n",
    "# for index, landmark in enumerate(landmarks):\n",
    "#     print(f\"#{index}: x={landmark.x:.2f}, y={landmark.y:.2f}, z={landmark.z:.2f}, visibility={landmark.visibility:.2f}\")\n"
   ],
   "metadata": {
    "id": "XK8lffVzo4rd",
    "ExecuteTime": {
     "end_time": "2025-08-05T12:23:44.142239Z",
     "start_time": "2025-08-05T12:23:44.128270Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# for landmark in landmarks:\n",
    "#     x = int(landmark.x * image.shape[1])\n",
    "#     y = int(landmark.y * image.shape[0])\n",
    "#     cv2.circle(image, (x, y), 4, (0, 255, 0), -1)\n",
    "\n",
    "# cv2.imshow('Pose Landmarks', image)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJTi2TTLsWfg",
    "outputId": "9a1f8e77-e03c-4b5e-d568-03a294c91075",
    "ExecuteTime": {
     "end_time": "2025-08-05T12:23:44.173352Z",
     "start_time": "2025-08-05T12:23:44.157691Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  }
 ]
}
